Задача 1

Схема БД
--------

Servers
--------
id (PK)
name
host
port
username
password
is_active


Files
--------
id (PK)
server_id (FK -> Servers.id)
file_name
status ("pending", "downloaded", "uploaded", "error")
downloaded_at
uploaded_at
error_message

===============


Модули приложения
-----------------
core - настройки и воркер
db - модуль работы с БД (сессия, модели)
routes - контроллеры (эндпоинты)
schemas - схемы сущностей
services - хэндлеры (методы)
tasks - задачи Celery


Алгоритм работы скачивания файлов
---------------------------------
- Адреса sftp серверов добавляется вручную через API
- Приложение fastapi каждые 5 секунд проверяет на sftp серверах наличие новых файлов
- Инфрмация о файлах хранится в БД. Происходит проверка всех файлов на sftp сервера.
  Если файл еще не был скачан, то происходит прямое скачивание с sftp сервера на MinIO.

Все вышеперечисленные задачи выполняются параллельно и вызываются последовательно (проверка серверов -> проверка файлов -> скачивание недостающих файлов).

Получение информации о новых файлах на sftp сервере работает через polling (каждые 5 сек), так как это самый простой и подходящий вариант, так как
возможно лучшие решения как inode нужно настраивать на самом sftp сервере (не все поддерживают и по условию ТЗ я не умею доступ), а watchdog работает с локальным хранилищем (придется делать копию папки с файлами из sftp сервера)

=========================

Предусловия из ТЗ:
Файлы складываются в определенный каталог на SFTP сервере


Подводные камни
---------------

- Проблемы с подключением к sftp серверу. Необходимо реализовать механизм повторных попыток с экспоненциальной задержкой (1, 2, 4 ... сек)
- Один и тот же файл может быть импортирован несколько раз.
  Необходимо хранить уникальные идентификаторы файлов (например, хэш содержимого, имя+размер+время_изменения, inode если сервер поддерживает)
  в БД и перед обработкой проверять, существует ли файл в базе.
- Файлы могут достигать нескольких гигабайт, что может привести к переполнению памяти. Можно использовать потоковое скачивание или по частям.
- Несколько экземпляров сервиса (gunicorn) могут одновременно работать с одним сервером. Можно использовать Redis Lock например.
- Загрузка файла может прерваться из-за сетевых проблем или сбоев. Можно хранить состояние загрузки в БД или использовать multipart-upload в MinIO для возобновления загрузки.
- Большое количество файлов и серверов может перегрузить систему. Можно ограничить количество одновременно выполняемых задач Celery (например до 10) или
  использовать rabbitmq для управления очередями.
- Сложности с отслеживанием состояния системы. Тут помогут логгирование и мониторинг (Prometheus, Grafana, Sentry)
- Проблемы с безопасностью. Ключи хранить нужно в безопасном хранилище (например HashiCorp Vault), следить чтобы в docker контейнеры не попали ключи.
  Также нужно настроить https.
